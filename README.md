# dbt Streaming Platform â€” Medallion Architecture on Databricks

End-to-end implementation of the **Medallion Architecture** (Bronze â†’ Silver â†’ Gold) using **dbt Core** and **Databricks Unity Catalog** for a streaming platform with complete Databricks Asset Bundle deployment and GitHub Actions CI/CD.

---

## ğŸ“‹ Table of Contents
- [Project Structure](#project-structure)
- [Architecture Overview](#architecture-overview)
- [Quick Start](#quick-start)
- [Layer Details](#layer-details)
- [Common dbt Commands](#common-dbt-commands)
- [Databricks Asset Bundle Deployment](#databricks-asset-bundle-deployment)
- [GitHub Actions CI/CD](#github-actions-cicd)
- [Configuration & Credentials](#configuration--credentials)
- [Local Development](#local-development)
- [Troubleshooting](#troubleshooting)
- [Best Practices](#best-practices)
- [Resources](#resources)

---

## Project Structure

```
dbt_streaming_db/
â”œâ”€â”€ dbt_project.yml              # dbt project configuration
â”œâ”€â”€ profiles.yml                 # Databricks connection (copy to ~/.dbt/)
â”œâ”€â”€ packages.yml                 # dbt_utils + dbt_expectations
â”œâ”€â”€ schema.yml                   # Sources, model docs & tests
â”œâ”€â”€ databricks.yml               # Asset bundle configuration
â”‚
â”œâ”€â”€ seeds/                       # Raw CSV seed data
â”‚   â”œâ”€â”€ raw_users.csv
â”‚   â”œâ”€â”€ raw_shows.csv
â”‚   â”œâ”€â”€ raw_watches.csv
â”‚   â””â”€â”€ raw_ratings.csv
â”‚
â”œâ”€â”€ macros/                      # Reusable SQL macros
â”‚   â”œâ”€â”€ generate_custom_schema.sql   # Schema routing macro
â”‚   â””â”€â”€ generate_record_hash.sql     # MD5 hash helper
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ 010_bronze/              # Raw ingestion â€” light curation + audit cols
â”‚   â”‚   â”œâ”€â”€ bronze_users.sql
â”‚   â”‚   â”œâ”€â”€ bronze_shows.sql
â”‚   â”‚   â”œâ”€â”€ bronze_watches.sql
â”‚   â”‚   â””â”€â”€ bronze_ratings.sql
â”‚   â”‚
â”‚   â”œâ”€â”€ 020_silver/              # Cleaned, validated, type-cast
â”‚   â”‚   â”œâ”€â”€ silver_users.sql
â”‚   â”‚   â”œâ”€â”€ silver_shows.sql
â”‚   â”‚   â”œâ”€â”€ silver_watches.sql
â”‚   â”‚   â””â”€â”€ silver_ratings.sql
â”‚   â”‚
â”‚   â””â”€â”€ 030_gold/                # Business-level facts & dimensions
â”‚       â”œâ”€â”€ dim_shows.sql
â”‚       â”œâ”€â”€ fct_watches.sql
â”‚       â””â”€â”€ fct_ratings.sql
â”‚
â”œâ”€â”€ snapshots/
â”‚   â””â”€â”€ snap_users.sql           # SCD Type-2 on silver_users
â”‚
â”œâ”€â”€ tests/                       # Data quality tests
â”‚   â”œâ”€â”€ assert_completed_watches_have_ratings.sql
â”‚   â”œâ”€â”€ assert_completion_pct_valid.sql
â”‚   â”œâ”€â”€ assert_fct_watches_valid_ratings.sql
â”‚   â””â”€â”€ assert_ratings_valid_range.sql
â”‚
â”œâ”€â”€ analyses/                    # Ad-hoc analytics queries
â”‚   â”œâ”€â”€ monthly_viewing_trend.sql
â”‚   â”œâ”€â”€ show_ratings_by_genre.sql
â”‚   â””â”€â”€ top_users_by_engagement.sql
â”‚
â”œâ”€â”€ notebooks/                   # Databricks notebooks for job execution
â”‚   â”œâ”€â”€ dbt_seed.py
â”‚   â”œâ”€â”€ dbt_run_bronze.py
â”‚   â”œâ”€â”€ dbt_run_silver.py
â”‚   â”œâ”€â”€ dbt_snapshot.py
â”‚   â”œâ”€â”€ dbt_run_gold.py
â”‚   â””â”€â”€ dbt_test.py
â”‚
â”œâ”€â”€ .github/workflows/
â”‚   â””â”€â”€ deploy.yml               # GitHub Actions CI/CD pipeline
â”‚
â”œâ”€â”€ setup.sh / setup.bat         # Automated local setup scripts
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ .env.example                 # Environment template
â”œâ”€â”€ .gitignore                   # Git configuration
â””â”€â”€ README.md                    # This file
```

---

## Architecture Overview

```
Source CSVs (seeds)
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BRONZE  (streaming_dev.bronze.*)       â”‚
â”‚  â€¢ Raw data, no transformation          â”‚
â”‚  â€¢ Audit cols: _loaded_at, _source,     â”‚
â”‚    _row_hash                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SILVER  (streaming_dev.silver.*)       â”‚
â”‚  â€¢ Type casting & null filtering        â”‚
â”‚  â€¢ String normalisation (trim/upper)    â”‚
â”‚  â€¢ Derived: rating_sentiment            â”‚
â”‚  â€¢ Referential integrity tests          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GOLD    (streaming_dev.gold.*)         â”‚
â”‚  â€¢ dim_shows     â€” quality_tier, length â”‚
â”‚  â€¢ fct_watches   â€” views/completion     â”‚
â”‚  â€¢ fct_ratings   â€” enriched reviews     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Unity Catalog three-level namespace:**
```
<catalog>.<schema>.<table>
 streaming_dev.bronze.bronze_users
 streaming_dev.silver.silver_watches
 streaming_dev.gold.fct_ratings
```

---

## Quick Start

### 1. Prerequisites

- **Databricks Account**: Access to workspace
- **Python 3.9+**: For dbt
- **Databricks CLI**: v0.200.0+ (for Asset Bundle deployment)
- **GitHub Account**: For CI/CD (optional for local dev)

### 2. Install Required Tools

```bash
pip install -r requirements.txt
```

### 3. Automated Local Setup

```bash
# Linux/macOS
chmod +x setup.sh
./setup.sh

# Windows
setup.bat
```

### 4. Manual Configuration

```bash
mkdir -p ~/.dbt
cp profiles.yml ~/.dbt/
# Edit ~/.dbt/profiles.yml with your credentials
```

### 5. Create Databricks Resources

```sql
CREATE CATALOG IF NOT EXISTS streaming_dev;
CREATE SCHEMA IF NOT EXISTS streaming_dev.bronze;
CREATE SCHEMA IF NOT EXISTS streaming_dev.silver;
CREATE SCHEMA IF NOT EXISTS streaming_dev.gold;
```

### 6. Run dbt Pipeline

```bash
dbt seed --profiles-dir ~/.dbt
dbt run --profiles-dir ~/.dbt
dbt test --profiles-dir ~/.dbt
dbt docs generate --profiles-dir ~/.dbt
dbt docs serve --profiles-dir ~/.dbt
```

---

## Layer Details

### ğŸŸ¤ Bronze â€” Raw Ingestion

| Model | Source | Transformations |
|---|---|---|
| `bronze_users` | `raw_users.csv` | Add audit columns (_loaded_at, _source, _row_hash) |
| `bronze_shows` | `raw_shows.csv` | Add audit columns |
| `bronze_watches` | `raw_watches.csv` | Add audit columns |
| `bronze_ratings` | `raw_ratings.csv` | Add audit columns |

### ğŸ©¶ Silver â€” Cleaned & Validated

| Model | Key Transformations |
|---|---|
| `silver_users` | Trim, initcap name, lowercase email, uppercase country, drop nulls |
| `silver_shows` | Type cast, validate rating_avg 0-5 |
| `silver_watches` | Lowercase status, cast date, validate completion_pct 0-1 |
| `silver_ratings` | Type cast, validate rating 1-5, compute sentiment (Positive/Neutral) |

### ğŸŸ¡ Gold â€” Business-Ready

| Model | Purpose |
|---|---|
| `dim_shows` | Show dimension with quality_tier and series_length |
| `fct_watches` | Watch facts with completion, ratings, time dimensions |
| `fct_ratings` | Enriched ratings with show, watch, and user context |

---

## Common dbt Commands

### Run Models by Layer

```bash
# Bronze layer
dbt run --select "010_bronze" --profiles-dir ~/.dbt

# Silver layer
dbt run --select "020_silver" --profiles-dir ~/.dbt

# Gold layer
dbt run --select "030_gold" --profiles-dir ~/.dbt

# All layers
dbt run --profiles-dir ~/.dbt

# Specific model
dbt run --select "silver_users" --profiles-dir ~/.dbt
```

### Testing & Validation

```bash
# All tests
dbt test --profiles-dir ~/.dbt

# By layer
dbt test --select "silver" --profiles-dir ~/.dbt

# By model
dbt test --select "fct_watches" --profiles-dir ~/.dbt

# Verbose output
dbt test -v --profiles-dir ~/.dbt
```

### Snapshots (SCD Type-2)

```bash
dbt snapshot --profiles-dir ~/.dbt
dbt snapshot --select "snap_users" --profiles-dir ~/.dbt
```

### Documentation

```bash
dbt docs generate --profiles-dir ~/.dbt
dbt docs serve --profiles-dir ~/.dbt
# Opens: http://localhost:8000
```

### Parsing & Validation

```bash
dbt parse --profiles-dir ~/.dbt
dbt debug --profiles-dir ~/.dbt
dbt compile --profiles-dir ~/.dbt
dbt ls --profiles-dir ~/.dbt
```

---

## Databricks Asset Bundle Deployment

### Prerequisites

1. **Databricks CLI v0.200.0+**
   ```bash
   curl https://raw.githubusercontent.com/databricks/databricks-cli/db-connect/install.sh | sh
   ```

2. **Databricks Resources**: Catalog, schemas, and cluster configured

3. **Environment Variables**
   ```bash
   export DATABRICKS_HOST="https://adb-<workspace-id>.azuredatabricks.net"
   export DATABRICKS_TOKEN="dapi<your-token>"
   export DBT_CLUSTER_ID="<cluster-id>"
   export ALERT_EMAIL="<email@example.com>"
   ```

### Create Databricks Resources

```sql
-- Create catalogs
CREATE CATALOG IF NOT EXISTS streaming_dev;
CREATE CATALOG IF NOT EXISTS streaming_prod;

-- Create schemas
CREATE SCHEMA IF NOT EXISTS streaming_dev.bronze;
CREATE SCHEMA IF NOT EXISTS streaming_dev.silver;
CREATE SCHEMA IF NOT EXISTS streaming_dev.gold;
```

### Create Compute Cluster

- **Name**: dbt-cluster
- **Runtime**: 13.3 LTS Scala 2.12
- **Worker Type**: i3.xlarge
- **Min Workers**: 1, Max Workers: 8
- **Auto-termination**: 30 minutes

### Deploy Bundle

```bash
# Validate
databricks bundle validate

# Deploy to dev
databricks bundle deploy --target dev

# Deploy to prod
databricks bundle deploy --target prod
```

### Run Jobs

```bash
# List jobs
databricks jobs list

# Run job
databricks jobs run-now --job-id <job-id>

# View history
databricks jobs list-runs --job-id <job-id>
```

---

## GitHub Actions CI/CD

### Setup GitHub Secrets

Go to repository â†’ Settings â†’ Secrets and variables â†’ Actions

| Secret | Value |
|---|---|
| DATABRICKS_HOST | `https://adb-<workspace-id>.azuredatabricks.net` |
| DATABRICKS_TOKEN | Your PAT token |
| DATABRICKS_HTTP_PATH | `/sql/1.0/warehouses/<warehouse-id>` |
| DBT_CLUSTER_ID | Your cluster ID |
| ALERT_EMAIL | Your email |

### CI/CD Workflow

```
PR â†’ Lint & Test
  â†“
Approve & Merge
  â†“
Push to develop â†’ Deploy to Dev
  â†“
Push to main â†’ Deploy to Prod (with approval)
```

### Triggers

- **Pull Request**: Lint and test only
- **Push to develop**: Deploy to dev
- **Push to main**: Deploy to prod

---

## Configuration & Credentials

### Environment Variables

```bash
# Databricks
export DATABRICKS_HOST="https://adb-<workspace-id>.azuredatabricks.net"
export DATABRICKS_TOKEN="dapi<your-token>"
export DATABRICKS_HTTP_PATH="/sql/1.0/warehouses/<warehouse-id>"

# dbt & Deployment
export DBT_CLUSTER_ID="<cluster-id>"
export ALERT_EMAIL="<email@example.com>"
```

### .env File

```bash
cp .env.example .env
# Edit with your values
```

### dbt Profiles (~/.dbt/profiles.yml)

```yaml
databricks_medallion:
  target: dev
  outputs:
    dev:
      type: databricks
      method: http
      catalog: streaming_dev
      schema: default
      host: your-workspace.azuredatabricks.net
      http_path: /sql/1.0/warehouses/your-warehouse-id
      token: "{{ env_var('DATABRICKS_TOKEN') }}"
      threads: 4
```

---

## Local Development

### Setup

```bash
# Clone and setup
git clone <repo>
cd <repo>

# Create virtual environment
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows

# Install dependencies
pip install -r requirements.txt

# Or use setup script
./setup.sh
```

### Run Models

```bash
# Test connection
dbt debug --profiles-dir ~/.dbt

# Build pipeline
dbt seed --profiles-dir ~/.dbt
dbt run --profiles-dir ~/.dbt
dbt test --profiles-dir ~/.dbt

# Before pushing
dbt build --profiles-dir ~/.dbt
```

### Git Workflow

```bash
# Create feature branch
git checkout -b feature/new-model

# Make changes and test
dbt build --profiles-dir ~/.dbt

# Commit with descriptive message
git commit -m "feat: add watch completion trend analysis"

# Push and create PR
git push origin feature/new-model
```

---

## Troubleshooting

### dbt Errors

**"Target profile name dev not found"**
```bash
mkdir -p ~/.dbt
cp profiles.yml ~/.dbt/
```

**"Catalog not found"**
```sql
CREATE CATALOG IF NOT EXISTS streaming_dev;
```

**"Cluster not found"**
```bash
databricks clusters list
export DBT_CLUSTER_ID="<correct-id>"
```

**"Model selection returned no results"**
```bash
dbt parse
dbt ls
```

### Databricks Issues

**Authentication failed**
```bash
export DATABRICKS_HOST="https://adb-<workspace-id>.azuredatabricks.net"
export DATABRICKS_TOKEN="dapi<your-token>"
dbt debug --profiles-dir ~/.dbt
```

**Test failures**
```bash
dbt test --select "test_name" -v --profiles-dir ~/.dbt
```

### GitHub Actions Issues

- Check workflow logs in Actions tab
- Verify all GitHub secrets are set
- Ensure Databricks resources exist
- Check cluster is running

---

## Best Practices

### Development

1. **Test locally before pushing**
   ```bash
   dbt build --profiles-dir ~/.dbt
   ```

2. **Use feature branches**
   ```bash
   git checkout -b feature/streaming-analytics
   ```

3. **Descriptive commit messages**
   - `feat: add monthly viewing trend analysis`
   - `fix: correct watch completion calculation`
   - `docs: update model descriptions`

4. **Document models in YAML**
   ```yaml
   - name: fct_watches
     description: "Fact table for viewing sessions"
     columns:
       - name: watch_id
         tests: [not_null, unique]
   ```

5. **Full build before production**
   ```bash
   dbt build --fail-fast
   ```

### Testing

- Add tests for critical models
- Use schema tests in YAML
- Create SQL tests for complex logic
- Run tests before every commit

### Production

- Monitor job execution logs daily
- Update dbt packages monthly
- Review and optimize slow models
- Use GitHub environment approval for prod

---

## Resources

### Official Documentation
- [dbt Documentation](https://docs.getdbt.com/)
- [dbt + Databricks](https://docs.getdbt.com/reference/warehouse-setups/databricks-setup)
- [Databricks Asset Bundles](https://docs.databricks.com/en/dev-tools/bundles/index.html)
- [GitHub Actions](https://docs.github.com/en/actions)

### Databricks Resources
- [Medallion Architecture](https://www.databricks.com/glossary/medallion-architecture)
- [Unity Catalog](https://docs.databricks.com/en/data-governance/unity-catalog/index.html)
- [Databricks Jobs](https://docs.databricks.com/en/workflows/jobs/index.html)

---

**Version**: 1.0.0 | **Last Updated**: February 2026
